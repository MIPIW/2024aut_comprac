{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proejct elements\n",
    "- readme.ipynb: reports about methods, goal, results\n",
    "- preprocess.ipynb: preprocessing, initialize tokenizer, prepare dataset\n",
    "- train_model.ipynb: initialize model, trainingArguments and trainer, train and save model\n",
    "- run.sh: execution codes, and its result(best steps in terms of accuracy) as annotation\n",
    "\n",
    "# Methods\n",
    "- convert stock price data with korean string\n",
    "- to initialize model and train. \n",
    "- variable hyperparameters: learning rate, weight decay\n",
    "- fixed hyperparameters: layers, attention heads, sequence length\n",
    "- two controls: tokenizers\n",
    "    - first(indiv): digits and units are separatedly tokenized(예: 일/천/오/백)\n",
    "    - second(joint): digits and units are jointedly tokenized(예: 일천/오백)\n",
    "\n",
    "# Goal(what to see?)\n",
    "## As a homework\n",
    "1. preprocess the stock data\n",
    "    - convert the number into string\n",
    "    - preprocess the string fit to the tokenizer\n",
    "2. initialize GPT2 model from huggingface, using config with custom hyperparameters\n",
    "3. train and compare results\n",
    "\n",
    "## as a toy project\n",
    "1. the price data fluctuate more on low units then on the higher units\n",
    "2. according to this inductive bias, when the tokens are splitted jointedly, only the digits + lower_units varies much\n",
    "3. on the other hand, when the tokens are splitted individually, as the lower level units vary much, its digits as well as lower units would varies much, which makes model to predict the subsequent tokens(values) much harder\n",
    "4. so, I expect the accuracies of 'indiv' tokenzer would be more lower than that of 'joint' tokenizer. \n",
    "\n",
    "\n",
    "# result: \n",
    "- as we can check the evaluation result in annotation, except for the large learning rate which both model scores low, the individual tokenizer model performs much better than the joint tokenizer, which the hypothesis is rejected(note that this is without verification of statisticallity). \n",
    "- i did not decode the generated output and check how much it differs(e.g. Gen: 일십만오천이백, True: 일십만오천삼백사십, Diff: 140) so the results take more chance to be explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
